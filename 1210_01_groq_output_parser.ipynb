{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhRljuBFjG42ZFuYZ0dtb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/24_fall_textmining_NLP/blob/main/1210_01_groq_output_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Groq API](https://wikidocs.net/259655)**\n",
        "\n",
        "- https://console.groq.com/playground\n",
        "- https://python.langchain.com/docs/how_to/sequence/ **(Langchain Tutorial)**\n",
        "- https://wikidocs.net/book/14314 **(한글판 랑체인 튜토리얼)**"
      ],
      "metadata": {
        "id": "UmjMoIobUZr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_key = userdata.get('groq')"
      ],
      "metadata": {
        "id": "GuxZqRXkU-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-dOigfFVNyr",
        "outputId": "efa79afb-8a04-4151-b075-05a1f93a420e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ptXYOaAUUAR"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# ChatGroq 모델 초기화\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\", # google/gemma-2-9b-it\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 템플릿 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"당신은 친절하고 유익한 AI 조수입니다. 한국의 역사와 문화에 대해 잘 알고 있습니다.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])"
      ],
      "metadata": {
        "id": "xyOjVepeVG2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain 생성\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "qBrVIXdhVb3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# 질문 리스트\n",
        "questions = [\n",
        "    \"한글의 창제 원리는 무엇인가요?\",\n",
        "    \"김치의 역사와 문화적 중요성에 대해 설명해주세요.\",\n",
        "    \"조선시대의 과거 제도에 대해 간단히 설명해주세요.\"\n",
        "]\n",
        "\n",
        "# 각 질문에 대한 답변 생성\n",
        "for question in questions:\n",
        "    response = chain.invoke({\"question\": question})\n",
        "    print(f\"질문: {question}\")\n",
        "    print(f\"답변: {response.content}\\n\") # Use response.content to access the text"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZyLdPjwVxb0",
        "outputId": "f20fdda3-0e84-4209-f4c9-311b67533d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문: 한글의 창제 원리는 무엇인가요?\n",
            "답변: 한글의 창제 원리는 매우 흥미롭습니다! \n",
            "\n",
            "세종대왕은 백성들이 글을 읽고 써 알 수 있도록 **\"사람의 발음과 소리\"**를 직접적으로 표현하는 글자 체계를 만들고자 했습니다. \n",
            "\n",
            "**다음은 한글 창제의 핵심 원리입니다:**\n",
            "\n",
            "* **자음과 모음의 분리:** 한글은 자음과 모음을 분리하여 사용합니다. 자음은 발음의 수단(예: 혀, 입술, 기침)을 기반으로 만들었고, 모음은 음성 공간(예: 입 모양)을 기반으로 만들어졌습니다.\n",
            "* **음성학적 분석:** 한글은 발음의 원리를 분석하여 자음과 모음을 표현하는 기호를 만들었습니다. \n",
            "* **음성 기호의 표현:** 자음은 발음을 하는 기관의 움직임을, 모음은 발음 시 모양을 직접적으로 표현하며, 이러한 기호들이 조합될 때 다양한 소리를 만들어내도록 설계되었습니다.\n",
            "\n",
            "**예를 들어, \"ㄱ\"은 기침소리를 나타내는 기호이고, \"ㅏ\"는 입술 모양을 나타내는 기호입니다.** 이러한 기\n",
            "\n",
            "질문: 김치의 역사와 문화적 중요성에 대해 설명해주세요.\n",
            "답변: ## 김치: 한국의 역사와 문화를 담은 맛\n",
            "\n",
            "김치는 한국인의 삶에서 뗄 수 없는 식탁의 주인공입니다. 단순한 음식을 넘어 한국의 역사와 문화를 반영하는 중요한 문화유산이죠. \n",
            "\n",
            "**역사:**\n",
            "\n",
            "* 김치의 역사는 매우 오래되었습니다. 기원전 2천년경 거쳐온 삼국시대부터 김치를 즐겼다는 기록이 남아있으며, 당나라의 경우도 김치 benzeri fermente 된 음식을 즐겼다는 기록이 있습니다.\n",
            "* 10세기부터는 국내 재래김치 양조 기술이 발전하고 다양한 종류의 김치가 등장했습니다.\n",
            "* 조선시대에는 김치가 국가적으로 중요하게 여겨졌습니다. 곡식이 부족할 때나 겨울철 식량 문제를 해결하기 위해 김치를 저장하는 문화가 시행되었습니다. \n",
            "* 쌀과 함께 김치는 한국인의 주식이 되었고, 탄탄한 식량 기반을 제공했습니다.\n",
            "\n",
            "**문화적 중요성:**\n",
            "\n",
            "* **건강:** 김치는 유산균이 풍부하여 소화를 돕고 면역력을 강화하는 효능이 있습니다. \n",
            "\n",
            "질문: 조선시대의 과거 제도에 대해 간단히 설명해주세요.\n",
            "답변: 조선시대 과거 제도는 **한성을 꿈꾸는 청년들의 열정과 지혜를 시험하는, 엄격하면서도 정치적 중심을 이루는 시스템**이었습니다. \n",
            "\n",
            "**핵심은 '공정한 기회'와 '능력 인정'**에 있었죠! \n",
            "\n",
            "* **누구든 시험을 통해 관료가 될 수 있었습니다.** \n",
            "  * 천민이라도 뛰어난 학업 성취를 통해  '주관', '시험관' 등 높은 직위를 달성할 수 있었죠.\n",
            "* **과거 시험은 매우 어려웠습니다.** \n",
            "  * 4개의 단계를 거쳐 면접(시험)과 답변(예술문)을 통해 능력을 숙달해야 했습니다.\n",
            "* **과거는 조선 시대의 궁극적인 사회적 이동 사슬**이라 할 수 있습니다. \n",
            "  * 과거에 합격하면 관료가 되고, 사회적으로 높은 지위를 얻을 수 있었습니다.\n",
            "\n",
            "과거 시험은 단순히 지식을 묻는 것이 아니라, **조선 사회의 가치관과 윤리, 정치적 사상**까지 평가하는 시스템이었습니다. \n",
            "\n",
            "조선\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gradio로 만들어줘\n",
        "\n",
        "!pip install gradio langchain-groq --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGtlTlFVVr17",
        "outputId": "e62679db-b88a-4707-921e-51d4f322a738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# ChatGroq 모델 초기화\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"당신은 친절하고 유익한 AI 조수입니다. 한국의 역사와 문화에 대해 잘 알고 있습니다.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# Chain 생성\n",
        "chain = prompt | llm\n",
        "\n",
        "def predict(message):\n",
        "    response = chain.invoke({\"question\": message})\n",
        "    return response.content\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean History & Culture Q&A\",\n",
        "    description=\"Ask me anything about Korean history and culture!\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "8Ty2K_MgdmBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRqW9QKTV9HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# template 정의. {country}는 변수로, 이후에 값이 들어갈 자리를 의미\n",
        "template = \"{country}의 수도는 어디인가요?\"\n",
        "\n",
        "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
        "prompt_template = PromptTemplate.from_template(template) # Change prompt to prompt_template\n",
        "\n",
        "# prompt 생성. format 메소드를 이용하여 변수에 값을 넣어줌\n",
        "prompt_string = prompt_template.format(country=\"대한민국\") # Create a new variable to hold the formatted string\n",
        "\n",
        "\n",
        "# chain 생성\n",
        "chain = prompt_template | llm  # Use the original prompt_template object in the chain"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FCPTlFtKcUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6NUhLEhcFvp",
        "outputId": "806564e5-da84-4485-fa9e-663474a1fd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')\n",
              "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7e6f5fcf63b0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7e6f5fb12350>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=300)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# country 변수에 입력된 값이 자동으로 치환되어 수행됨\n",
        "chain.invoke(\"대한민국\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9X7nIMuochHy",
        "outputId": "0138d3c8-256f-42ec-a1bd-588751538b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'대한민국의 수도는 **서울**입니다. 😊 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **출력파서(Output Parser)**\n",
        "### **LangChain의 출력파서는 언어 모델(LLM)의 출력을 더 유용하고 구조화된 형태로 변환하는 중요한 컴포넌트**"
      ],
      "metadata": {
        "id": "GhSFT1D_gG6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Fewshot Prompt**"
      ],
      "metadata": {
        "id": "A-bKDWWfdgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Few-Shot Prompting Template for Korean Historical Figures\n",
        "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert in providing concise, informative descriptions of Korean historical figures.\n",
        "    Always provide a response in the following format:\n",
        "    - Name: [Full Name]\n",
        "    - Era: [Historical Period]\n",
        "    - Key Achievements: [3-4 most significant contributions]\n",
        "    - Impact: [Lasting influence on Korean history]\"\"\"),\n",
        "\n",
        "    # Few-shot examples to guide the model's response\n",
        "    (\"human\", \"Tell me about King Sejong\"),\n",
        "    (\"ai\", \"\"\"- Name: 세종대왕 (King Sejong the Great)\n",
        "- Era: Joseon Dynasty (1418-1450)\n",
        "- Key Achievements:\n",
        "  1. Created Hangul (Korean alphabet)\n",
        "  2. Advanced scientific and cultural development\n",
        "  3. Expanded agricultural techniques\n",
        "  4. Promoted education and scholarship\n",
        "- Impact: Considered one of the most important monarchs in Korean history, revolutionized communication and cultural understanding\"\"\"),\n",
        "\n",
        "    (\"human\", \"Tell me about Admiral Yi Sun-sin\"),\n",
        "    (\"ai\", \"\"\"- Name: 이순신 (Admiral Yi Sun-sin)\n",
        "- Era: Joseon Dynasty (Late 16th century)\n",
        "- Key Achievements:\n",
        "  1. Defended Korea against Japanese invasions\n",
        "  2. Invented the Turtle Ship (Geobukseon)\n",
        "  3. Won 23 consecutive naval battles\n",
        "  4. Exemplified military strategy and leadership\n",
        "- Impact: National hero who prevented Japanese conquest and saved Korea during the Imjin War\"\"\"),\n",
        "\n",
        "    # The actual query will be added dynamically\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = few_shot_prompt | llm\n",
        "\n",
        "# Gradio interface function\n",
        "def predict(historical_figure):\n",
        "    response = chain.invoke({\"historical_figure\": historical_figure})\n",
        "    return response.content\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean Historical Figures Insights\",\n",
        "    description=\"Get structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "EVykw5VBdg5R",
        "outputId": "df4a9934-35f5-4267-ead7-e0db64ba16b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d4ac511d2f04f87bde.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d4ac511d2f04f87bde.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. PydanticOuputParser**\n",
        "- **PydanticOutputParser 는 언어 모델의 출력을 더 구조화된 정보로 변환 하는 데 도움이 되는 클래스**\n",
        "- **단순 텍스트 형태의 응답 대신, 사용자가 필요로 하는 정보를 명확하고 체계적인 형태로 제공**"
      ],
      "metadata": {
        "id": "swVoOFbpdh4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Define a Pydantic model for structured historical figure information\n",
        "class HistoricalFigure(BaseModel):\n",
        "    name: str = Field(description=\"Full name of the historical figure\")\n",
        "    korean_name: str = Field(description=\"Name in Korean characters\")\n",
        "    birth_year: int = Field(description=\"Year of birth\")\n",
        "    death_year: int = Field(description=\"Year of death\")\n",
        "    era: str = Field(description=\"Historical period\")\n",
        "    key_achievements: List[str] = Field(description=\"3-4 most significant contributions\")\n",
        "    impact: str = Field(description=\"Lasting influence on Korean history\")\n",
        "    interesting_fact: str = Field(description=\"A unique or surprising detail about the figure\")\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a PydanticOutputParser\n",
        "parser = PydanticOutputParser(pydantic_object=HistoricalFigure)\n",
        "\n",
        "# Create a prompt template that includes output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures.\n",
        "\n",
        "    {format_instructions}\n",
        "\n",
        "    Please provide comprehensive information about the requested historical figure.\"\"\"),\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "        # Convert Pydantic model to a formatted string\n",
        "        return \"\\n\".join([\n",
        "            f\"**Name:** {result.name} ({result.korean_name})\",\n",
        "            f\"**Lived:** {result.birth_year} - {result.death_year}\",\n",
        "            f\"**Era:** {result.era}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.key_achievements],\n",
        "            f\"\\n**Historical Impact:** {result.impact}\",\n",
        "            f\"\\n**Interesting Fact:** {result.interesting_fact}\"\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "XY7_WtRTer4J",
        "outputId": "42903696-5bb5-40b5-c497-f6a1f99c2ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a9d914bd1a0c2bb24a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a9d914bd1a0c2bb24a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. JsonOutputParser**\n",
        "- **출력 파서는 사용자가 원하는 JSON 스키마를 지정할 수 있게 해주며, 그 스키마에 맞게 LLM에서 데이터를 조회하여 결과를 도출**\n",
        "- **LLM이 데이터를 정확하고 효율적으로 처리하여 원하는 형태의 JSON을 생성하기 위해서는, 모델의 용량(여기서는 인텔리전스를 의미**\n",
        "- **예. llama-70B 이 llama-8B 보다 용량이 크다) 이 충분해야 한다는 점을 참고**"
      ],
      "metadata": {
        "id": "pQ4ILdl8euii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a JsonOutputParser\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# Create a prompt template that includes JSON output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures in a strict JSON format.\n",
        "\n",
        "    Respond with a JSON object containing the following keys:\n",
        "    - name: Full name of the historical figure\n",
        "    - korean_name: Name in Korean characters\n",
        "    - birth_year: Year of birth (integer)\n",
        "    - death_year: Year of death (integer)\n",
        "    - era: Historical period\n",
        "    - key_achievements: List of most significant contributions\n",
        "    - impact: Lasting influence on Korean history\n",
        "    - interesting_fact: A unique or surprising detail about the figure\n",
        "\n",
        "    {format_instructions}\"\"\"),\n",
        "    (\"human\", \"Tell me about {historical_figure}\")\n",
        "])\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "\n",
        "        # Format the JSON result as a readable markdown string\n",
        "        formatted_output = \"\\n\".join([\n",
        "            f\"**Name:** {result.get('name', 'N/A')} ({result.get('korean_name', 'N/A')})\",\n",
        "            f\"**Lived:** {result.get('birth_year', 'N/A')} - {result.get('death_year', 'N/A')}\",\n",
        "            f\"**Era:** {result.get('era', 'N/A')}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.get('key_achievements', [])],\n",
        "            f\"\\n**Historical Impact:** {result.get('impact', 'N/A')}\",\n",
        "            f\"\\n**Interesting Fact:** {result.get('interesting_fact', 'N/A')}\"\n",
        "        ])\n",
        "\n",
        "        # Also return the raw JSON for reference\n",
        "        return formatted_output + f\"\\n\\n**Raw JSON:**\\n```json\\n{json.dumps(result, indent=2, ensure_ascii=False)}```\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures (JSON)\",\n",
        "    description=\"Get detailed, structured JSON information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "lqCGFhvZgEY_",
        "outputId": "d0be6a49-169c-44a5-d8ea-131c48b8b31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://eced003eac4134965f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eced003eac4134965f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. PandasDataFrameOutputParser**\n",
        "- **Pandas DataFrame은 Python 프로그래밍 언어에서 널리 사용되는 데이터 구조로, 데이터 조작 및 분석을 위해 흔히 사용되며 구조화된 데이터를 다루기 위한 포괄적인 도구 세트를 제공하여, 데이터 정제, 변환 및 분석과 같은 작업에 다양하게 활용**"
      ],
      "metadata": {
        "id": "2-0T-uYug6Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# 예시 데이터를 사용하여 데이터 프레임 생성 함수 정의\n",
        "def get_historical_figures(figure_name=None):\n",
        "    # 한국 역사적 인물들에 대한 예시 데이터\n",
        "    figures_list = [\n",
        "        {\n",
        "            \"name\": \"Yi Sun-sin\",\n",
        "            \"korean_name\": \"이순신\",\n",
        "            \"birth_year\": 1545,\n",
        "            \"death_year\": 1598,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"Admiral\",\n",
        "            \"key_achievement\": \"Defeated Japanese Navy during the Imjin War\",\n",
        "            \"historical_significance\": \"National hero known for his naval victories against Japan\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sejong the Great\",\n",
        "            \"korean_name\": \"세종대왕\",\n",
        "            \"birth_year\": 1397,\n",
        "            \"death_year\": 1450,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"King of Joseon\",\n",
        "            \"key_achievement\": \"Created the Korean alphabet Hangul\",\n",
        "            \"historical_significance\": \"One of the most respected kings, greatly improved Korean culture and literacy\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Kim Gu\",\n",
        "            \"korean_name\": \"김구\",\n",
        "            \"birth_year\": 1876,\n",
        "            \"death_year\": 1949,\n",
        "            \"era\": \"Korean Empire / Japanese Occupation\",\n",
        "            \"primary_role\": \"Politician\",\n",
        "            \"key_achievement\": \"Leader of the Korean independence movement\",\n",
        "            \"historical_significance\": \"Major figure in the movement for Korean independence from Japan\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # 데이터를 pandas DataFrame으로 변환\n",
        "    df = pd.DataFrame(figures_list)\n",
        "\n",
        "    # 특정 인물 이름을 입력받았을 경우 필터링\n",
        "    if figure_name:\n",
        "        df = df[(df['korean_name'] == figure_name) | (df['name'] == figure_name)]\n",
        "\n",
        "    # 데이터가 없을 경우 메시지를 담은 DataFrame 반환\n",
        "    if df.empty:\n",
        "        return pd.DataFrame([{\"Message\": f\"No information found for {figure_name}\"}])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Gradio 인터페이스 정의\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figures,\n",
        "    inputs=\"text\",  # 특정 역사적 인물 이름을 입력받기 위해 텍스트 입력 사용\n",
        "    outputs=\"dataframe\",  # 데이터 프레임을 출력\n",
        "    title=\"Structured Korean Historical Figures (Pandas DataFrame)\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# 인터페이스 실행\n",
        "iface.launch()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "VnXGlfYvg_3x",
        "outputId": "bd3566ba-e8ba-478f-b629-bcdad01d3d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9b7153e0b8d38cf412.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9b7153e0b8d38cf412.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core.output_parsers as parsers\n",
        "print(dir(parsers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1hYTW3hSsR",
        "outputId": "86b709f1-6e37-4522-b730-f15477868d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BaseCumulativeTransformOutputParser', 'BaseGenerationOutputParser', 'BaseLLMOutputParser', 'BaseOutputParser', 'BaseTransformOutputParser', 'CommaSeparatedListOutputParser', 'JsonOutputKeyToolsParser', 'JsonOutputParser', 'JsonOutputToolsParser', 'ListOutputParser', 'MarkdownListOutputParser', 'NumberedListOutputParser', 'PydanticOutputParser', 'PydanticToolsParser', 'SimpleJsonOutputParser', 'StrOutputParser', 'XMLOutputParser', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'format_instructions', 'json', 'list', 'openai_tools', 'pydantic', 'string', 'transform', 'xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnUM5Gt4kKV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0dVkaBjiYz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}