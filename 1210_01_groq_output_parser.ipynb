{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw+zXy/hifm/mrC6WkOwQ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/24_fall_textmining_NLP/blob/main/1210_01_groq_output_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Groq API](https://wikidocs.net/259655)**\n",
        "\n",
        "- https://console.groq.com/playground\n",
        "- https://python.langchain.com/docs/how_to/sequence/ **(Langchain Tutorial)**\n",
        "- https://wikidocs.net/book/14314 **(í•œê¸€íŒ ë‘ì²´ì¸ íŠœí† ë¦¬ì–¼)**"
      ],
      "metadata": {
        "id": "UmjMoIobUZr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_key = userdata.get('groq')"
      ],
      "metadata": {
        "id": "GuxZqRXkU-aA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-dOigfFVNyr",
        "outputId": "d37aa4ee-b06c-4797-b351-5c608634369f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/108.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ptXYOaAUUAR"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# ChatGroq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\", # google/gemma-2-9b-it\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYFHZ-QVMZJ1",
        "outputId": "80c57cb9-fb30-4f29-df59-a344380a1d74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c9bff765b10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c9bff7663e0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=300)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"ì•ˆë…•í•˜ì„¸ìš”?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "xzvPaWZnMRG6",
        "outputId": "61ef764d-9752-4a8e-fc5b-74f18cb63ac0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e172f47a785f>:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm.predict(\"ì•ˆë…•í•˜ì„¸ìš”?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹  ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])"
      ],
      "metadata": {
        "id": "xyOjVepeVG2-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain ìƒì„±\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "qBrVIXdhVb3N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "source": [
        "# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
        "questions = [\n",
        "    \"í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "    \"ê¹€ì¹˜ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì  ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
        "    \"ì¡°ì„ ì‹œëŒ€ì˜ ê³¼ê±° ì œë„ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
        "]\n",
        "\n",
        "# ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
        "for question in questions:\n",
        "    response = chain.invoke({\"question\": question})\n",
        "    print(f\"ì§ˆë¬¸: {question}\")\n",
        "    print(f\"ë‹µë³€: {response.content}\\n\") # Use response.content to access the text\n",
        "    print(\"*\" * 150)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZyLdPjwVxb0",
        "outputId": "bf27d1c6-d8e9-4c9d-be8d-0c4eacde1292"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì§ˆë¬¸: í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
            "ë‹µë³€: ë„¤, ì €ëŠ” í•œêµ­ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤! ğŸ˜Š\n",
            "\n",
            "í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” **ì„¸ìƒ ëª¨ë“  ì†Œë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê¸€ìë¥¼ ë§Œë“¤ê³ ì í•˜ëŠ” íƒì›”í•œ ì´ë…**ê³¼ **ìŒì„±í•™ì  ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì²´ê³„ì ì¸ êµ¬ì¡°**ì— ìˆìŠµë‹ˆë‹¤. \n",
            "\n",
            "ì„¸ì¢…ëŒ€ì™•ê»˜ì„œëŠ” ë°±ì„±ë“¤ì´ ì‰½ê²Œ ê¸€ì„ ìµí ìˆ˜ ìˆë„ë¡ **ìì—°ì˜ ì†Œë¦¬**ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ìƒˆë¡œìš´ ë¬¸ìë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. \n",
            "\n",
            "* **ììŒ:** ììŒì€ **ì…ìˆ , í˜€, ì‡ëª¸ ë“± ë°œìŒê¸°ê´€ì˜ ëª¨ì–‘**ì„ ë³¸ë–  ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.  \n",
            "* **ëª¨ìŒ:** ëª¨ìŒì€ **ì–¸ì–´ì˜ ëª¨ì–‘**ê³¼ **ë°œìŒ ë²”ìœ„**ë¥¼ ê³ ë ¤í•˜ì—¬ **í•˜ëŠ˜, ë•…, ì‚¬ëŒ**ì˜ ìƒì§•ì„ ë‹´ì•„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. \n",
            "\n",
            "ê° ììŒê³¼ ëª¨ìŒì€ ì¡°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ì†Œë¦¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆê³ , ì´ëŠ” **ìœ ë‹ˆí¬í•˜ê³  íš¨ìœ¨ì ì¸ ë¬¸ì ì²´ê³„**ë¥¼ í˜•ì„±í•©ë‹ˆë‹¤. \n",
            "\n",
            "í•œê¸€ì€ ë‹¨ìˆœí•œ ë¬¸ìë¥¼ ë„˜ì–´, **í•œêµ­ ë¬¸í™”ì™€ ì •ì‹ ì„ ë‹´ê³  ìˆëŠ” í›Œë¥­í•œ ìœ ì‚°**ì…ë‹ˆë‹¤. âœ¨\n",
            "\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "ì§ˆë¬¸: ê¹€ì¹˜ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì  ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "ë‹µë³€: ## ê¹€ì¹˜: í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ë‹´ì€ ë°œíš¨ ìŒì‹\n",
            "\n",
            "ê¹€ì¹˜ëŠ” í•œêµ­ì˜ ëŒ€í‘œì ì¸ ìŒì‹ì´ì ë¬¸í™”ì  ìƒì§•ë¬¼ì…ë‹ˆë‹¤. ë‹¨ìˆœí•œ ë°œíš¨ ì‹í’ˆì„ ë„˜ì–´ í•œêµ­ì¸ì˜ ì‚¶ê³¼ ì—­ì‚¬, ê·¸ë¦¬ê³  ê°€ì¹˜ê´€ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.\n",
            "\n",
            "**1. ê¹€ì¹˜ì˜ ì—­ì‚¬:**\n",
            "\n",
            "* **ê³ ëŒ€ë¶€í„° ì‹œì‘ëœ ë°œíš¨ ë¬¸í™”:** ê¹€ì¹˜ì˜ ì—­ì‚¬ëŠ” ì‹ ë¼ ì‹œëŒ€ê¹Œì§€ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°‘ë‹ˆë‹¤. ë‹¹ì‹œì—ë„ ë°°ì¶”ë¥¼ ë°œíš¨ì‹œì¼œ ë¨¹ì—ˆë˜ ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, ì´ëŸ¬í•œ ë°œíš¨ ë¬¸í™”ëŠ” ë¶ë°© ìœ ëŸ½ì˜ ê¹€ì¹˜ì™€ ë‹®ì€ ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
            "* **í•œë°˜ë„ì˜ í™ê³¼ ì”¨ì•—:** ê¹€ì¹˜ëŠ” í•œë°˜ë„ì˜ íŠ¹ì • ê¸°í›„ì™€ í† ì–‘ì— ììƒí•˜ëŠ” ë°°ì¶”, ê³ ì¶”, ì “ê°ˆ ë“±ì˜ ì¬ë£Œë¥¼ í™œìš©í•˜ì—¬ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ì´ëŸ¬í•œ ì§€ì—­ì  íŠ¹ì§•ì€ ê¹€ì¹˜ì˜ ë‹¤ì–‘í•œ ë§›ê³¼ í–¥ì„ ë§Œë“¤ì–´ë‚´ëŠ” ì¤‘ìš”í•œ ìš”ì¸ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "* **ê³„ì ˆì˜ íë¦„ ì†ì—ì„œ:** ê¹€ì¹˜ëŠ” ê²¨ìš¸ ë™ì•ˆ ë¨¹ì„ ìˆ˜ ìˆëŠ” ì €ì¥ ì‹í’ˆìœ¼ë¡œ, ë†ê²½ ì‚¬íšŒì˜ ì‚¶ê³¼ ë°€ì ‘í•˜ê²Œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ë§¤ê¸° ê²¨ìš¸ì€ ê¹€ì¹˜ë¥¼ ë‹´ê·¸ëŠ” ì¤‘ìš”í•œ ì‹œê°„ì´ì—ˆìœ¼ë©°, ê°€\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "ì§ˆë¬¸: ì¡°ì„ ì‹œëŒ€ì˜ ê³¼ê±° ì œë„ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "ë‹µë³€: ë„¤, ì¡°ì„ ì‹œëŒ€ ê³¼ê±° ì œë„ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.\n",
            "\n",
            "ì¡°ì„ ì‹œëŒ€ ê³¼ê±°ëŠ” **ì§€ì‹ê³¼ ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ì§ì— ì„ìš©í•˜ëŠ” ì‹œí—˜ ì œë„**ì˜€ìŠµë‹ˆë‹¤. \n",
            "\n",
            "**ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:**\n",
            "\n",
            "* **ì„ê¸ˆì´ ì§ì ‘ ì±„ìš©:** ê³¼ê±°ëŠ” ì™•ì´ ì§ì ‘ ê´€ì§ì„ ì±„ìš©í•˜ëŠ” ì¤‘ìš”í•œ ì œë„ì˜€ìŠµë‹ˆë‹¤. ì¦‰, ì¼ì • ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ì‚¬ëŒì´ë¼ë©´ ëˆ„êµ¬ë“  ì™•ì—ê²Œ ì§ì ‘ ê´€ì§ì„ ì²­ì›í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
            "* **4ê³¼ 3ë‹¨ê³„ ì‹œí—˜:** ê³¼ê±°ì‹œí—˜ì€ ì‚¬ë§ˆ, ìƒì›, ì§„ì‚¬, \n",
            "  ì–´ë ¤ìš´ í•™ë¬¸ì„ ìŒ“ê³  ëŠ¥ë ¥ì„ ê°–ì¶˜ ì‚¬ëŒë“¤ì´ ê´€ì§ì— ì„ëª…ë  ìˆ˜ ìˆë„ë¡ ì—„ê²©í•˜ê³  ì²´ê³„ì ì¸ ì‹œí—˜ ê³¼ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤. \n",
            "  ì´ë¥¼ **ì‚¬ë§ˆ, ìƒì›, ì§„ì‚¬, ê¸‰ì œ**ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
            "* **ë¬´ê²Œ ì¤‘ì‹¬ ì‹œí—˜:** ì‹œí—˜ì€ ë‹¹ì‹œì˜ ìœ ìˆ˜ í•™ìë“¤ì´ ê°ê´€ì ì¸ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ **ìœ¨ê³¡ ì´ì´ë¥¼ ë¹„ë¡¯í•œ í•™ìë“¤ì´ ì§ì ‘ ë¬¸ì œë¥¼ ë§Œë“¤ê³  í‰ê°€**í–ˆìŠµë‹ˆë‹¤.\n",
            "* **ì§€ë°© ê³¼ê±°:** ê° ì§€ì—­ì—ì„œë„ ê³¼ê±°ê°€ ì—´\n",
            "\n",
            "******************************************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gradioë¡œ ë§Œë“¤ì–´ì¤˜\n",
        "!pip install gradio langchain-groq --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGtlTlFVVr17",
        "outputId": "5998bcb8-920d-45d3-99ff-fcbaed6cf24d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **gradio**"
      ],
      "metadata": {
        "id": "5HmYnOjdNAh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# ChatGroq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# Chain ìƒì„±\n",
        "chain = prompt | llm\n",
        "\n",
        "def predict(message):\n",
        "    response = chain.invoke({\"question\": message})\n",
        "    return response.content\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean History & Culture Q&A\",\n",
        "    description=\"Ask me anything about Korean history and culture!\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "8Ty2K_MgdmBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "a3d3c3ee-3f41-4de6-d139-0f43c2426bec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0c44c33c24d9772e3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c44c33c24d9772e3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# template ì •ì˜. {country}ëŠ” ë³€ìˆ˜ë¡œ, ì´í›„ì— ê°’ì´ ë“¤ì–´ê°ˆ ìë¦¬ë¥¼ ì˜ë¯¸\n",
        "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
        "\n",
        "# from_template ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
        "prompt_template = PromptTemplate.from_template(template) # Change prompt to prompt_template\n",
        "\n",
        "# prompt ìƒì„±. format ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ ë³€ìˆ˜ì— ê°’ì„ ë„£ì–´ì¤Œ\n",
        "prompt_string = prompt_template.format(country=\"ëŒ€í•œë¯¼êµ­\") # Create a new variable to hold the formatted string\n",
        "\n",
        "\n",
        "# chain ìƒì„±\n",
        "chain = prompt_template | llm  # Use the original prompt_template object in the chain"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FCPTlFtKcUBZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6NUhLEhcFvp",
        "outputId": "30525e6b-330e-4d77-a726-602a0340d8fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')\n",
              "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c9bf5c95960>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c9bf5c94c10>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=300)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# country ë³€ìˆ˜ì— ì…ë ¥ëœ ê°’ì´ ìë™ìœ¼ë¡œ ì¹˜í™˜ë˜ì–´ ìˆ˜í–‰ë¨\n",
        "chain.invoke(\"ëŒ€í•œë¯¼êµ­\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9X7nIMuochHy",
        "outputId": "36836247-ab0b-405c-81df-6480bde9292e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤. ğŸ‡°ğŸ‡·  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"í”„ë‘ìŠ¤\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "smJIyqEKNQTi",
        "outputId": "e298cf7d-2f51-4527-a59f-4ad00173339c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” **íŒŒë¦¬**ì…ë‹ˆë‹¤. ğŸ‡«ğŸ‡·  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ì¶œë ¥íŒŒì„œ(Output Parser)**\n",
        "### **LangChainì˜ ì¶œë ¥íŒŒì„œëŠ” ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶œë ¥ì„ ë” ìœ ìš©í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ìš”í•œ ì»´í¬ë„ŒíŠ¸**"
      ],
      "metadata": {
        "id": "GhSFT1D_gG6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Fewshot Prompt**"
      ],
      "metadata": {
        "id": "A-bKDWWfdgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Few-Shot Prompting Template for Korean Historical Figures\n",
        "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert in providing concise, informative descriptions of Korean historical figures.\n",
        "    Always provide a response in the following format:\n",
        "    - Name: [Full Name]\n",
        "    - Era: [Historical Period]\n",
        "    - Key Achievements: [3-4 most significant contributions]\n",
        "    - Impact: [Lasting influence on Korean history]\"\"\"),\n",
        "\n",
        "    # Few-shot examples to guide the model's response\n",
        "    (\"human\", \"Tell me about King Sejong\"),\n",
        "    (\"ai\", \"\"\"- Name: ì„¸ì¢…ëŒ€ì™• (King Sejong the Great)\n",
        "            - Era: Joseon Dynasty (1418-1450)\n",
        "            - Key Achievements:\n",
        "            1. Created Hangul (Korean alphabet)\n",
        "            2. Advanced scientific and cultural development\n",
        "            3. Expanded agricultural techniques\n",
        "            4. Promoted education and scholarship\n",
        "            - Impact: Considered one of the most important monarchs in Korean history, revolutionized communication and cultural understanding\"\"\"),\n",
        "\n",
        "    (\"human\", \"Tell me about Admiral Yi Sun-sin\"),\n",
        "    (\"ai\", \"\"\"- Name: ì´ìˆœì‹  (Admiral Yi Sun-sin)\n",
        "            - Era: Joseon Dynasty (Late 16th century)\n",
        "            - Key Achievements:\n",
        "            1. Defended Korea against Japanese invasions\n",
        "            2. Invented the Turtle Ship (Geobukseon)\n",
        "            3. Won 23 consecutive naval battles\n",
        "            4. Exemplified military strategy and leadership\n",
        "            - Impact: National hero who prevented Japanese conquest and saved Korea during the Imjin War\"\"\"),\n",
        "\n",
        "    # The actual query will be added dynamically\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = few_shot_prompt | llm\n",
        "\n",
        "# Gradio interface function\n",
        "def predict(historical_figure):\n",
        "    response = chain.invoke({\"historical_figure\": historical_figure})\n",
        "    return response.content\n",
        "\n",
        "predict('ê²½ë³µê¶')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EVykw5VBdg5R",
        "outputId": "4d14f5d0-e4d6-4a46-a198-7473e9764809"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"- Name: ê²½ë³µê¶ (Gyeongbokgung)\\n            - Era: Joseon Dynasty (1395-1910)\\n            - Key Achievements:\\n            1. Largest and most magnificent royal palace in Seoul\\n            2. Represents Joseon Dynasty's architectural and artistic grandeur\\n            3. Served as the main residence of Joseon kings\\n            4. Preserved as a UNESCO World Heritage Site\\n            - Impact: A symbol of Korean heritage and a popular tourist destination showcasing traditional Korean architecture and history.\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean Historical Figures Insights\",\n",
        "    description=\"Get structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "MLY3_MFYOCM2",
        "outputId": "3608ef37-4b91-4c12-93df-08fce839827d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96a782355aafdb70b2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://96a782355aafdb70b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. PydanticOuputParser**\n",
        "- **PydanticOutputParser ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë” êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜ í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í´ë˜ìŠ¤**\n",
        "- **ë‹¨ìˆœ í…ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µ ëŒ€ì‹ , ì‚¬ìš©ìê°€ í•„ìš”ë¡œ í•˜ëŠ” ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ì²´ê³„ì ì¸ í˜•íƒœë¡œ ì œê³µ**"
      ],
      "metadata": {
        "id": "swVoOFbpdh4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Define a Pydantic model for structured historical figure information\n",
        "class HistoricalFigure(BaseModel):\n",
        "    name: str = Field(description=\"Full name of the historical figure\")\n",
        "    korean_name: str = Field(description=\"Name in Korean characters\")\n",
        "    birth_year: int = Field(description=\"Year of birth\")\n",
        "    death_year: int = Field(description=\"Year of death\")\n",
        "    era: str = Field(description=\"Historical period\")\n",
        "    key_achievements: List[str] = Field(description=\"3-4 most significant contributions\")\n",
        "    impact: str = Field(description=\"Lasting influence on Korean history\")\n",
        "    interesting_fact: str = Field(description=\"A unique or surprising detail about the figure\")\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a PydanticOutputParser\n",
        "parser = PydanticOutputParser(pydantic_object=HistoricalFigure)\n",
        "\n",
        "# Create a prompt template that includes output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures.\n",
        "\n",
        "    {format_instructions}\n",
        "\n",
        "    Please provide comprehensive information about the requested historical figure.\"\"\"),\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "        # Convert Pydantic model to a formatted string\n",
        "        return \"\\n\".join([\n",
        "            f\"**Name:** {result.name} ({result.korean_name})\",\n",
        "            f\"**Lived:** {result.birth_year} - {result.death_year}\",\n",
        "            f\"**Era:** {result.era}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.key_achievements],\n",
        "            f\"\\n**Historical Impact:** {result.impact}\",\n",
        "            f\"\\n**Interesting Fact:** {result.interesting_fact}\"\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "XY7_WtRTer4J",
        "outputId": "42903696-5bb5-40b5-c497-f6a1f99c2ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a9d914bd1a0c2bb24a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a9d914bd1a0c2bb24a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. JsonOutputParser**\n",
        "- **ì¶œë ¥ íŒŒì„œëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì •í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ê·¸ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ LLMì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ê²°ê³¼ë¥¼ ë„ì¶œ**\n",
        "- **LLMì´ ë°ì´í„°ë¥¼ ì •í™•í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì›í•˜ëŠ” í˜•íƒœì˜ JSONì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ”, ëª¨ë¸ì˜ ìš©ëŸ‰(ì—¬ê¸°ì„œëŠ” ì¸í…”ë¦¬ì „ìŠ¤ë¥¼ ì˜ë¯¸**\n",
        "- **ì˜ˆ. llama-70B ì´ llama-8B ë³´ë‹¤ ìš©ëŸ‰ì´ í¬ë‹¤) ì´ ì¶©ë¶„í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ì°¸ê³ **"
      ],
      "metadata": {
        "id": "pQ4ILdl8euii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a JsonOutputParser\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# Create a prompt template that includes JSON output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures in a strict JSON format.\n",
        "\n",
        "    Respond with a JSON object containing the following keys:\n",
        "    - name: Full name of the historical figure\n",
        "    - korean_name: Name in Korean characters\n",
        "    - birth_year: Year of birth (integer)\n",
        "    - death_year: Year of death (integer)\n",
        "    - era: Historical period\n",
        "    - key_achievements: List of most significant contributions\n",
        "    - impact: Lasting influence on Korean history\n",
        "    - interesting_fact: A unique or surprising detail about the figure\n",
        "\n",
        "    {format_instructions}\"\"\"),\n",
        "    (\"human\", \"Tell me about {historical_figure}\")\n",
        "])\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "\n",
        "        # Format the JSON result as a readable markdown string\n",
        "        formatted_output = \"\\n\".join([\n",
        "            f\"**Name:** {result.get('name', 'N/A')} ({result.get('korean_name', 'N/A')})\",\n",
        "            f\"**Lived:** {result.get('birth_year', 'N/A')} - {result.get('death_year', 'N/A')}\",\n",
        "            f\"**Era:** {result.get('era', 'N/A')}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.get('key_achievements', [])],\n",
        "            f\"\\n**Historical Impact:** {result.get('impact', 'N/A')}\",\n",
        "            f\"\\n**Interesting Fact:** {result.get('interesting_fact', 'N/A')}\"\n",
        "        ])\n",
        "\n",
        "        # Also return the raw JSON for reference\n",
        "        return formatted_output + f\"\\n\\n**Raw JSON:**\\n```json\\n{json.dumps(result, indent=2, ensure_ascii=False)}```\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures (JSON)\",\n",
        "    description=\"Get detailed, structured JSON information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "lqCGFhvZgEY_",
        "outputId": "d0be6a49-169c-44a5-d8ea-131c48b8b31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://eced003eac4134965f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eced003eac4134965f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. PandasDataFrameOutputParser**\n",
        "- **Pandas DataFrameì€ Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¡œ, ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•´ í”íˆ ì‚¬ìš©ë˜ë©° êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ í¬ê´„ì ì¸ ë„êµ¬ ì„¸íŠ¸ë¥¼ ì œê³µí•˜ì—¬, ë°ì´í„° ì •ì œ, ë³€í™˜ ë° ë¶„ì„ê³¼ ê°™ì€ ì‘ì—…ì— ë‹¤ì–‘í•˜ê²Œ í™œìš©**"
      ],
      "metadata": {
        "id": "2-0T-uYug6Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í”„ë ˆì„ ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
        "def get_historical_figures(figure_name=None):\n",
        "    # í•œêµ­ ì—­ì‚¬ì  ì¸ë¬¼ë“¤ì— ëŒ€í•œ ì˜ˆì‹œ ë°ì´í„°\n",
        "    figures_list = [\n",
        "        {\n",
        "            \"name\": \"Yi Sun-sin\",\n",
        "            \"korean_name\": \"ì´ìˆœì‹ \",\n",
        "            \"birth_year\": 1545,\n",
        "            \"death_year\": 1598,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"Admiral\",\n",
        "            \"key_achievement\": \"Defeated Japanese Navy during the Imjin War\",\n",
        "            \"historical_significance\": \"National hero known for his naval victories against Japan\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sejong the Great\",\n",
        "            \"korean_name\": \"ì„¸ì¢…ëŒ€ì™•\",\n",
        "            \"birth_year\": 1397,\n",
        "            \"death_year\": 1450,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"King of Joseon\",\n",
        "            \"key_achievement\": \"Created the Korean alphabet Hangul\",\n",
        "            \"historical_significance\": \"One of the most respected kings, greatly improved Korean culture and literacy\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Kim Gu\",\n",
        "            \"korean_name\": \"ê¹€êµ¬\",\n",
        "            \"birth_year\": 1876,\n",
        "            \"death_year\": 1949,\n",
        "            \"era\": \"Korean Empire / Japanese Occupation\",\n",
        "            \"primary_role\": \"Politician\",\n",
        "            \"key_achievement\": \"Leader of the Korean independence movement\",\n",
        "            \"historical_significance\": \"Major figure in the movement for Korean independence from Japan\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # ë°ì´í„°ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "    df = pd.DataFrame(figures_list)\n",
        "\n",
        "    # íŠ¹ì • ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥ë°›ì•˜ì„ ê²½ìš° í•„í„°ë§\n",
        "    if figure_name:\n",
        "        df = df[(df['korean_name'] == figure_name) | (df['name'] == figure_name)]\n",
        "\n",
        "    # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ë©”ì‹œì§€ë¥¼ ë‹´ì€ DataFrame ë°˜í™˜\n",
        "    if df.empty:\n",
        "        return pd.DataFrame([{\"Message\": f\"No information found for {figure_name}\"}])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figures,\n",
        "    inputs=\"text\",  # íŠ¹ì • ì—­ì‚¬ì  ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥ë°›ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ì…ë ¥ ì‚¬ìš©\n",
        "    outputs=\"dataframe\",  # ë°ì´í„° í”„ë ˆì„ì„ ì¶œë ¥\n",
        "    title=\"Structured Korean Historical Figures (Pandas DataFrame)\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
        "iface.launch()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "VnXGlfYvg_3x",
        "outputId": "bd3566ba-e8ba-478f-b629-bcdad01d3d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9b7153e0b8d38cf412.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9b7153e0b8d38cf412.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core.output_parsers as parsers\n",
        "print(dir(parsers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1hYTW3hSsR",
        "outputId": "86b709f1-6e37-4522-b730-f15477868d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BaseCumulativeTransformOutputParser', 'BaseGenerationOutputParser', 'BaseLLMOutputParser', 'BaseOutputParser', 'BaseTransformOutputParser', 'CommaSeparatedListOutputParser', 'JsonOutputKeyToolsParser', 'JsonOutputParser', 'JsonOutputToolsParser', 'ListOutputParser', 'MarkdownListOutputParser', 'NumberedListOutputParser', 'PydanticOutputParser', 'PydanticToolsParser', 'SimpleJsonOutputParser', 'StrOutputParser', 'XMLOutputParser', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'format_instructions', 'json', 'list', 'openai_tools', 'pydantic', 'string', 'transform', 'xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnUM5Gt4kKV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0dVkaBjiYz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}