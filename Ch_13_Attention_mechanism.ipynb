{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBtMWzw9ZYSx5cIPghYHQ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/24_fall_textmining_NLP/blob/main/Ch_13_Attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어텐션 메커니즘 쉽게 이해하기: 도서관에서 책 찾기 비유\n",
        "\n",
        "### 어텐션 메커니즘을 **도서관에서 원하는 책을 찾는 과정**으로 비유해 보겠습니다. 이 과정에서 **Query, Key, Value**가 각각 어떤 역할을 하는지 이해해봅시다.\n",
        "\n",
        "## 1. Query, Key, Value의 역할\n",
        "\n",
        "### Query (질문)\n",
        "- **Query**는 여러분이 찾고자 하는 책의 주제입니다.\n",
        "- 예를 들어, 여러분이 도서관 사서에게 \"**고양이에 대한 책을 찾고 싶어요**\"라고 요청하는 것이 **Query**에 해당합니다.\n",
        "\n",
        "### Key (키워드들)\n",
        "- 도서관에는 많은 책들이 있고, 각 책에는 **키워드**들이 정리되어 있습니다.\n",
        "- 예를 들어, 책에는 **\"고양이\", \"동물\", \"가족\", \"취미\"** 같은 키워드가 붙어 있습니다.\n",
        "- 즉, **Key**는 각 책의 주제나 특징을 나타내며, 이를 통해 책을 찾을 수 있게 해주는 정보입니다.\n",
        "\n",
        "### Value (책의 내용)\n",
        "- **Value**는 실제로 각 책의 **내용**입니다.\n",
        "- 사서가 찾은 책을 여러분에게 보여줄 때, 그 책의 전체 내용이 바로 **Value**입니다. 실제 정보를 담고 있는 것이죠.\n",
        "\n",
        "## 2. 어텐션 메커니즘의 동작 원리\n",
        "\n",
        "### 1. Query를 통해 관련된 책 찾기\n",
        "- 여러분은 사서에게 \"**고양이에 대한 책을 찾고 싶어요 (Query)**\"라고 요청합니다.\n",
        "- 사서는 도서관의 모든 책을 확인하며, 각 책에 붙어 있는 **Key (키워드)**와 여러분의 **Query**를 비교합니다.\n",
        "- **고양이**라는 키워드가 붙어 있는 책을 찾으면, 그 책이 여러분의 Query와 연관이 있다고 판단합니다.\n",
        "\n",
        "### 2. 유사도 점수 계산\n",
        "- 사서는 각 책의 키워드가 여러분의 요청과 **얼마나 잘 맞는지 계산**합니다.\n",
        "  - **고양이** 키워드가 있는 책은 높은 점수를 받습니다.\n",
        "  - 반면에 **가족**이나 **취미**와 같은 키워드가 있는 책은 고양이와 관련이 없으므로 낮은 점수를 받습니다.\n",
        "\n",
        "### 3. Softmax로 중요한 책 결정\n",
        "- 도서관에는 관련된 책이 여러 권 있을 수 있습니다.\n",
        "- 사서는 이 책들 중 가장 관련이 높은 것들을 선택하고, 각 책이 얼마나 관련이 있는지에 따라 **가중치**를 부여합니다.\n",
        "- 예를 들어, 고양이에 대한 책이 가장 관련이 높고, 동물 일반에 대한 책도 어느 정도 관련이 있을 수 있습니다.\n",
        "- 이 과정에서 사용되는 것이 **Softmax**입니다. 이를 통해 각 책이 얼마나 중요한지 결정하고, 그 중요도에 따라 책들을 추천합니다.\n",
        "\n",
        "### 4. Value를 반환\n",
        "- 이제, 사서는 여러분에게 책을 꺼내서 보여줍니다. 이 책의 내용이 바로 **Value**입니다.\n",
        "- 여러분이 원했던 정보에 따라, 사서는 관련 있는 책들을 더 많이, 덜 관련 있는 책은 적게 보여줄 수 있습니다.\n",
        "\n",
        "## 3. 전체적으로 이해하기\n",
        "\n",
        "- **Query**: 여러분이 알고 싶은 질문이나 찾고자 하는 주제입니다.\n",
        "- **Key**: 도서관의 모든 책에 붙어 있는 **키워드**와 같은 정보입니다. 이것을 통해 어떤 책이 여러분의 질문과 관련이 있는지를 찾습니다.\n",
        "- **Value**: 실제 **책의 내용**으로, 여러분이 읽고 정보를 얻을 수 있는 부분입니다.\n",
        "\n",
        "**어텐션 메커니즘**은 여러분이 도서관에서 책을 찾는 것처럼, 입력된 정보(토큰)들 사이에서 어떤 정보가 현재 찾고자 하는 내용(Query)과 관련이 있는지를 계산하고, 그 결과로 **중요한 정보를 더 많이 반영해 새로운 출력을 만드는 과정**이라고 할 수 있습니다.\n",
        "\n",
        "이를 통해 모델은 문장에서 중요한 부분에 더 많은 주의를 기울여 적절한 결과를 생성하게 되는 것입니다.\n",
        "\n",
        "---\n",
        "\n",
        "이렇게 비유를 통해 **Query, Key, Value**의 역할을 쉽게 이해할 수 있습니다. 어텐션 메커니즘은 정보를 효율적으로 찾고 반영하는 데 있어 핵심적인 역할을 합니다."
      ],
      "metadata": {
        "id": "LJi-ZBBXEitY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Query, Key, Value 벡터 정의\n",
        "define_query = torch.tensor([[1.0, 0.0, 1.0]])  # 여러분의 질문 (고양이에 대한 책을 찾고 싶어요)\n",
        "define_keys = torch.tensor([[1.0, 0.5, 1.0],  # 책 1: 고양이 관련 책\n",
        "                           [0.5, 1.0, 0.5],  # 책 2: 동물 일반 관련 책\n",
        "                           [0.0, 0.5, 1.0]])  # 책 3: 취미 관련 책\n",
        "define_values = torch.tensor([[10.0, 0.0, 5.0],   # 책 1의 내용\n",
        "                              [1.0, 2.0, 3.0],    # 책 2의 내용\n",
        "                              [0.0, 0.5, 1.0]])   # 책 3의 내용\n",
        "\n",
        "# 1. Query와 Key 간의 유사도 계산 (어텐션 스코어)\n",
        "attention_scores = torch.matmul(define_query, define_keys.T)\n",
        "print(f'{define_query.shape}, {define_keys.T.shape}')\n",
        "# Step 1 결과: tensor([[2., 1., 1.]])\n",
        "# Query와 각 Key 사이의 유사도를 계산한 결과입니다. 첫 번째 책(Key)과 가장 높은 유사도(2)를 가집니다.\n",
        "print(\"Step 1: Query와 Key 간의 유사도 계산\")\n",
        "print(attention_scores)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2pm7OFdVZ8X",
        "outputId": "303a14dd-7ce2-44df-c166-ff765e91d0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3]), torch.Size([3, 3])\n",
            "Step 1: Query와 Key 간의 유사도 계산\n",
            "tensor([[2., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Softmax를 사용해 유사도를 확률로 변환 (책이 얼마나 관련이 있는지 결정)\n",
        "attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "# Step 2 결과: tensor([[0.5761, 0.2119, 0.2119]])\n",
        "# Softmax를 사용해 각 책과의 유사도를 확률 값으로 변환한 결과입니다. 첫 번째 책이 57.61%로 가장 관련이 높습니다.\n",
        "print(\"\\nStep 2: Softmax를 사용한 유사도 확률로 변환\")\n",
        "print(attention_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITRHVvVkWgF7",
        "outputId": "cff57a4c-8b89-492f-d009-df81ef4a7189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2: Softmax를 사용한 유사도 확률로 변환\n",
            "tensor([[0.5761, 0.2119, 0.2119]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. 가중치를 사용해 Value 반환 (중요한 책 내용 반영)\n",
        "attention_output = torch.matmul(attention_weights, define_values)\n",
        "# Step 3 결과: tensor([[5.9731, 0.5299, 3.7284]])\n",
        "# 각 책의 내용을 가중치만큼 곱하여 합산한 결과입니다. 가장 관련이 높은 첫 번째 책의 내용이 더 많이 반영되었습니다.\n",
        "print(\"\\nStep 3: 가중치를 사용한 Value 반환\")\n",
        "print(attention_output)\n",
        "\n",
        "# 출력된 내용은 각 책의 내용을 가중치만큼 곱해서 합산한 결과로, 중요도가 높은 책의 내용이 더 반영됩니다.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3tFoV8WW6ml",
        "outputId": "43551158-3180-44cd-d154-4a6b3e46e633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: 가중치를 사용한 Value 반환\n",
            "tensor([[5.9731, 0.5299, 3.7284]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-unoIb-VaIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rvAtdHjVaLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# 도서관에서 책을 찾는 과정에 비유한 예시\n",
        "# 이 코드는 도서관에서 원하는 책을 찾고 해당 책의 내용을 요약하여 정보를 얻는 과정을 모델링합니다.\n",
        "# Query는 도서관에서 우리가 찾고자 하는 내용을 설명하는 요청입니다.\n",
        "# Key는 도서관에 있는 책들의 카탈로그입니다. 각 책이 무엇에 관한 것인지 설명하고 있습니다.\n",
        "# Value는 책의 실제 내용, 즉 우리가 얻고자 하는 정보입니다.\n",
        "\n",
        "# 예시 영어 문장 데이터 (도서관의 책 내용이라고 생각해 봅시다)\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"A fast blue hare leaps over a sleepy hound\",\n",
        "    \"The agile squirrel climbs up the tall oak tree\",\n",
        "    \"A slow turtle crawls under the green bush\",\n",
        "    \"The red bird flies across the blue sky\"\n",
        "]\n",
        "\n",
        "# 각 문장을 토큰화합니다. (책의 내용을 단어 단위로 나누는 과정)\n",
        "tokenized_sentences = [sentence.lower().split() for sentence in sentences]\n",
        "print(\"토큰화된 문장:\")\n",
        "print(tokenized_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQYkxZqPRfG0",
        "outputId": "ab8cecaa-3773-4817-a23b-8f7aa17437d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화된 문장:\n",
            "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'], ['a', 'fast', 'blue', 'hare', 'leaps', 'over', 'a', 'sleepy', 'hound'], ['the', 'agile', 'squirrel', 'climbs', 'up', 'the', 'tall', 'oak', 'tree'], ['a', 'slow', 'turtle', 'crawls', 'under', 'the', 'green', 'bush'], ['the', 'red', 'bird', 'flies', 'across', 'the', 'blue', 'sky']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Word2Vec 모델을 학습합니다. (각 단어를 벡터로 변환하여 표현하는 단계)\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=4, window=3, min_count=1, sg=0)\n",
        "print(\"\\nWord2Vec 모델 학습 완료.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIqsq0tzTNSv",
        "outputId": "b9fe6987-1270-481f-919c-feb3da40b812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec 모델 학습 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Query, Key, Value 벡터 생성\n",
        "# 예시로 'fox', 'hare', 'squirrel'에 대해 Query, Key, Value 벡터를 추출합니다.\n",
        "# 'fox'는 우리가 찾고자 하는 정보(Query), 'hare'는 관련 있는 책(Key), 'squirrel'은 최종 정보를 담고 있는 내용(Value)입니다.\n",
        "query_word = 'fox'  # 우리가 도서관에서 찾고자 하는 내용\n",
        "key_word = 'hare'    # 도서관에 있는 책의 주제\n",
        "value_word = 'squirrel'  # 도서관에서 찾은 책의 실제 내용\n",
        "\n",
        "# Query, Key, Value 벡터 계산\n",
        "query_vector = model.wv[query_word]\n",
        "key_vector = model.wv[key_word]\n",
        "value_vector = model.wv[value_word]\n",
        "\n",
        "print(\"\\nQuery 벡터 (단어 '{}'):\".format(query_word))\n",
        "print(query_vector)\n",
        "print(\"Key 벡터 (단어 '{}'):\".format(key_word))\n",
        "print(key_vector)\n",
        "print(\"Value 벡터 (단어 '{}'):\".format(value_word))\n",
        "print(value_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95BiytPkTQJM",
        "outputId": "20ea313f-cb19-44e6-dae9-1dc6d6ee87ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query 벡터 (단어 'fox'):\n",
            "[-0.18800586 -0.09841785 -0.18778937 -0.02326501]\n",
            "Key 벡터 (단어 'hare'):\n",
            "[ 0.12466763  0.2306477  -0.20380454  0.11230064]\n",
            "Value 벡터 (단어 'squirrel'):\n",
            "[-0.04335568  0.16771552  0.24913052 -0.1091353 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 어텐션 점수 계산 과정\n",
        "# Query와 Key의 내적(dot product)을 계산하여 유사도를 구합니다.\n",
        "# 이것은 우리가 찾고자 하는 내용(Query)와 책(Key) 간의 관련성을 계산하는 것입니다.\n",
        "attention_raw_score = np.dot(query_vector, key_vector)  # Query와 Key의 내적 계산\n",
        "print(\"\\n내적 (어텐션 원시 점수) - '{}'와 '{}'의 유사도:\".format(query_word, key_word))\n",
        "print(attention_raw_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZYjv6brTWWl",
        "outputId": "1852c020-0740-492e-a157-1a55075faadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "내적 (어텐션 원시 점수) - 'fox'와 'hare'의 유사도:\n",
            "-0.010478445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 소프트맥스를 사용하여 어텐션 점수를 확률로 변환합니다.\n",
        "# 책(Key)이 우리가 찾고자 하는 정보(Query)와 얼마나 관련이 있는지를 확률로 나타냅니다.\n",
        "attention_score = np.exp(attention_raw_score) / np.sum(np.exp([attention_raw_score]))\n",
        "print(\"\\n소프트맥스를 적용한 어텐션 스코어 (단어 '{}'과 관련된 확률):\".format(key_word))\n",
        "print(attention_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzdw9XJ1TsWy",
        "outputId": "caf78279-d4c0-4ee2-e37a-4286bbc60eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "소프트맥스를 적용한 어텐션 스코어 (단어 'hare'과 관련된 확률):\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 어텐션 스코어를 이용해 Value에 가중치를 부여하여 최종 컨텍스트 벡터 계산\n",
        "# 찾고자 하는 정보와 관련된 책의 내용(Value)을 어텐션 스코어로 가중합하여 최종 정보를 얻습니다.\n",
        "context_vector = attention_score * value_vector\n",
        "print(\"\\n컨텍스트 벡터 (어텐션 스코어가 적용된 '{}'):\".format(value_word))\n",
        "print(context_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yp61psqTxur",
        "outputId": "3b742cb5-6192-41d7-ee06-1d44c59c3b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "컨텍스트 벡터 (어텐션 스코어가 적용된 'squirrel'):\n",
            "[-0.04335568  0.16771552  0.24913052 -0.1091353 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cona0o25RfKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLvenUtkRfNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# 샘플 문장: \"고양이에 대한 책을 찾고 싶어요\", \"강아지에 대한 책을 찾고 싶어요\", \"새에 대한 책을 찾고 싶어요\"\n",
        "sentences = [\n",
        "    [\"고양이\", \"책\", \"찾고\", \"싶어요\"],\n",
        "    [\"강아지\", \"책\", \"찾고\", \"싶어요\"],\n",
        "    [\"호랑이\", \"책\", \"찾고\", \"싶어요\"],\n",
        "]\n",
        "\n",
        "# Word2Vec 모델을 학습하여 각 단어의 임베딩 벡터 생성\n",
        "# vector_size=3: 각 단어를 3차원 벡터로 표현\n",
        "# min_count=1: 최소 단어 빈도가 1 이상인 단어만 포함\n",
        "# window=3: 주변 단어의 최대 거리\n",
        "# sg=0: CBOW(Continuous Bag of Words) 알고리즘 사용\n",
        "model = Word2Vec(sentences, vector_size=3, min_count=1, sg=0)\n",
        "\n",
        "# 각 토큰의 임베딩 벡터 추출\n",
        "# tokens 리스트에는 분석하고자 하는 단어들이 포함되어 있음\n",
        "tokens = [\"고양이\", \"책\", \"찾고\", \"싶어요\"]\n",
        "\n",
        "# Query 벡터 설정\n",
        "# \"고양이\"에 해당하는 단어의 임베딩 벡터를 Query로 사용\n",
        "Q = model.wv[\"고양이\"]  # Query는 우리가 찾고자 하는 주제와 같음\n",
        "print(\"Query Vector (Q):\", Q)\n",
        "\n",
        "# Key 벡터 설정\n",
        "# 모든 토큰의 임베딩 벡터를 Key로 사용\n",
        "K = np.array([model.wv[token] for token in tokens])  # 각 단어의 벡터가 Key로 설정됨\n",
        "print(\"Key Vectors (K):\\n\", K)\n",
        "\n",
        "# Value 벡터 설정\n",
        "# 모든 토큰의 임베딩 벡터를 Value로 사용\n",
        "V = np.array([model.wv[token] for token in tokens])  # 각 단어의 벡터가 Value로 설정됨\n",
        "print(\"Value Vectors (V):\\n\", V)\n",
        "\n",
        "# 단계 1: Query와 Key 벡터의 내적을 통한 유사도 계산\n",
        "# 각 Key 벡터와 Query 벡터 간의 내적을 계산하여 유사도를 구함\n",
        "# 유사도는 Query와 각 Key가 얼마나 관련이 있는지를 나타냄\n",
        "print(K.shape, Q.shape)\n",
        "dot_products = np.dot(K, Q)  # Query와 Key 간의 내적을 통해 유사도를 계산\n",
        "print(\"Dot Products (유사도 값):\", dot_products)\n",
        "\n",
        "# 단계 2: Softmax를 사용하여 가중치 계산\n",
        "# 유사도 값을 Softmax 함수에 통과시켜 각 단어의 가중치를 계산\n",
        "# Softmax를 통해 유사도를 확률 분포로 변환하여 각 단어의 중요도를 결정함\n",
        "attention_weights = softmax(dot_products)\n",
        "print(\"Attention Weights (가중치):\", attention_weights)\n",
        "\n",
        "# 결과 해석하기\n",
        "# 각 토큰에 대해 가중치와 함께 출력하여 어떤 단어가 중요한지 확인\n",
        "# 가중치가 높을수록 Query와 해당 단어(Key)가 더 관련이 깊음을 의미\n",
        "for i, token in enumerate(tokens):\n",
        "    print(f\"Token: {token}, Weight: {attention_weights[i]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lls6bJnpGr8P",
        "outputId": "1a442103-10ae-4e09-a2b0-46546bc3e9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Vector (Q): [-0.06053392  0.09588599  0.03306246]\n",
            "Key Vectors (K):\n",
            " [[-0.06053392  0.09588599  0.03306246]\n",
            " [ 0.21529575  0.2990996  -0.16718094]\n",
            " [ 0.3003091  -0.31009832 -0.23722696]\n",
            " [-0.01787424  0.00788105  0.17011166]]\n",
            "Value Vectors (V):\n",
            " [[-0.06053392  0.09588599  0.03306246]\n",
            " [ 0.21529575  0.2990996  -0.16718094]\n",
            " [ 0.3003091  -0.31009832 -0.23722696]\n",
            " [-0.01787424  0.00788105  0.17011166]]\n",
            "(4, 3) (3,)\n",
            "Dot Products (유사도 값): [ 0.01395161  0.01011935 -0.05575628  0.00746199]\n",
            "Attention Weights (가중치): [0.25494772 0.25397253 0.23778114 0.25329855]\n",
            "Token: 고양이, Weight: 0.255\n",
            "Token: 책, Weight: 0.254\n",
            "Token: 찾고, Weight: 0.238\n",
            "Token: 싶어요, Weight: 0.253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Query 벡터 (Q)**  \n",
        "   - Query Vector (Q): `[-0.00987271 -0.25537467 0.32049143]`  \n",
        "   - Query 벡터는 '고양이'라는 단어의 벡터입니다. 이 벡터는 Word2Vec 모델이 학습하여 '고양이'라는 단어의 의미를 고차원 공간에서 표현한 것입니다.  \n",
        "   - 이 벡터는 '고양이'와 관련된 문맥을 잘 표현합니다.\n",
        "\n",
        "2. **Key 벡터 (K)**  \n",
        "   - Key Vectors (K):  \n",
        "     ```  \n",
        "     [[-0.00987271 -0.25537467  0.32049143]  \n",
        "      [ 0.30029878 -0.3100974  -0.23723243]  \n",
        "      [ 0.21529575  0.2990996  -0.16718094]  \n",
        "      [-0.01783989  0.00779883  0.17014965]]  \n",
        "     ```  \n",
        "   - 각 Key 벡터는 각각의 단어 ('고양이', '책', '찾고', '싶어요')에 해당하는 벡터입니다.  \n",
        "   - Key 벡터들은 Query 벡터와의 유사도를 측정하기 위해 사용됩니다. 이 유사도는 Query와 각 Key 간의 내적으로 계산됩니다.\n",
        "\n",
        "3. **Value 벡터 (V)**  \n",
        "   - Value Vectors (V):  \n",
        "     ```  \n",
        "     [[-0.00987271 -0.25537467  0.32049143]  \n",
        "      [ 0.30029878 -0.3100974  -0.23723243]  \n",
        "      [ 0.21529575  0.2990996  -0.16718094]  \n",
        "      [-0.01783989  0.00779883  0.17014965]]  \n",
        "     ```  \n",
        "   - Value 벡터들은 Key 벡터와 동일합니다. 이 벡터들은 최종적으로 가중합을 계산하여 컨텍스트 벡터를 만드는 데 사용될 수 있습니다.\n",
        "\n",
        "4. **Query와 Key 간의 내적을 통한 유사도 계산**  \n",
        "   - Dot Products (유사도 값): `[0.16802844, 0.00019529, -0.13208807, 0.05271601]`  \n",
        "   - 각 Key 벡터와 Query 벡터의 내적을 통해 유사도 값을 계산합니다.  \n",
        "   - '고양이' (Query)와 각 단어(Key) 간의 유사도가 벡터의 내적을 통해 결정됩니다.  \n",
        "   - 결과적으로, 각 값은 Query와 해당 단어(Key)의 관련성을 나타냅니다.  \n",
        "   - **'고양이'**와 가장 높은 유사도 값을 가지는 것은 자기 자신으로서 `0.168`입니다.  \n",
        "   - '책', '찾고', '싶어요'와의 유사도는 상대적으로 낮습니다.\n",
        "\n",
        "5. **Softmax를 통한 가중치 계산**  \n",
        "   - Attention Weights (가중치): `[0.28757823, 0.24314593, 0.21301837, 0.2562574]`  \n",
        "   - 유사도 값을 Softmax 함수에 통과시켜 가중치를 계산합니다.  \n",
        "   - Softmax를 통해 유사도 값을 확률 분포로 변환하여, 각 단어가 얼마나 중요한지를 나타내는 가중치가 됩니다.  \n",
        "   - 결과적으로 가중치 합은 1이 되며, 이 값들은 각 단어가 Query와 관련이 얼마나 깊은지를 나타냅니다.\n",
        "\n",
        "6. **각 토큰에 대한 가중치 해석**  \n",
        "   - Token: '고양이', Weight: `0.288`  \n",
        "   - Token: '책', Weight: `0.243`  \n",
        "   - Token: '찾고', Weight: `0.213`  \n",
        "   - Token: '싶어요', Weight: `0.256`  \n",
        "   - **'고양이'**의 가중치가 `0.288`로 가장 높습니다. 이는 당연히 Query와 동일한 단어이므로 가장 관련이 깊다고 판단되기 때문입니다.  \n",
        "   - **'싶어요'**와 **'책'**도 각각 `0.256`과 `0.243`의 가중치를 가지며, 이 단어들이 문장에서 '고양이'와 어느 정도 관련이 있다고 판단됩니다.  \n",
        "   - **'찾고'**의 가중치는 가장 낮은 `0.213`입니다. 이는 '고양이'라는 단어와의 문맥적 관련성이 다른 단어들에 비해 적다고 판단된 것입니다.\n",
        "\n",
        "### **전체 요약**  \n",
        "- 어텐션 메커니즘을 통해 **Query ('고양이')**와 각 단어(Key) 간의 유사도를 계산했습니다.  \n",
        "- 유사도 값을 Softmax를 사용해 각 단어에 대한 가중치를 구하고, 이를 통해 어떤 단어들이 Query와 가장 관련이 있는지 알 수 있었습니다.  \n",
        "- '고양이'와 자신이 가장 관련이 깊고, 그 다음으로 '싶어요', '책' 등이 관련이 있음을 알 수 있었습니다.  \n",
        "- 이 과정은 어텐션 메커니즘이 입력된 단어들 사이에서 중요한 정보를 강조하고, 그 정보를 최종 출력에 반영하는 방식과 동일합니다.\n"
      ],
      "metadata": {
        "id": "DiQugcO1LCcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어텐션 메커니즘의 동작 방식과 벡터 가중합 결과 이해하기\n",
        "\n",
        "## 1. Attention Weights 해석\n",
        "각 단어에 대해 계산된 Attention Weight는 **'love'**라는 단어와 얼마나 관련성이 높은지를 나타냅니다. 높은 가중치를 가진 단어일수록 'love'와 의미적으로 더 밀접한 관련이 있다는 뜻입니다.\n",
        "\n",
        "- **love: 0.2111**  \n",
        "  'love' 단어 자체가 가장 높은 가중치를 가지며, 이는 당연히 Query와 일치하기 때문입니다.\n",
        "  \n",
        "- **too: 0.1176, pets: 0.0835, great: 0.0783**  \n",
        "  이 단어들은 상대적으로 높은 유사성을 가진 단어들입니다. 'too'와 'love'는 자주 같이 쓰일 수 있는 맥락을 가질 수 있고, 'pets'나 'great' 역시 문장에서 긍정적인 감정을 나타내므로 높은 관련성을 가집니다.\n",
        "  \n",
        "- **cats: 0.0549, people: 0.0576, make: 0.0438**  \n",
        "  이 단어들은 'love'와의 유사성이 비교적 낮습니다. 이는 문맥적으로 'love'와 직접적인 연관성이 적기 때문입니다.\n",
        "\n",
        "## 2. Context Vector 해석\n",
        "Context Vector는 어텐션 가중치와 각 단어 벡터(Value)의 가중합을 통해 계산된 벡터입니다. 이 벡터는 **'love'**라는 Query와 관련된 중요한 정보들을 반영한 벡터입니다.\n",
        "\n",
        "- **[-0.01856888, 0.04018145, 0.05784318, -0.00914868, 0.02499559]**  \n",
        "  이 벡터는 'love'와 관련된 전체 문맥을 대표하는 벡터입니다. 이 컨텍스트 벡터는 모델이 'love'라는 단어와 어떤 단어들이 관련이 있는지를 파악한 후, 그 관계성을 반영한 최종적인 표현입니다.  \n",
        "  이 벡터는 이후 자연어 생성 작업이나, 다른 형태의 예측 작업에 사용할 수 있습니다.\n",
        "\n",
        "## 3. 요약\n",
        "- **Attention Weights**는 Query 단어 (**'love'**)와 도서관의 책(Key) 간의 관련성을 나타내는 가중치입니다. 높은 가중치를 받은 단어들은 'love'와 더 밀접한 연관이 있다고 볼 수 있습니다.\n",
        "- **Context Vector**는 어텐션 가중치를 반영해 전체 문맥을 종합적으로 표현한 벡터로, 이 벡터를 통해 'love'라는 단어가 전체 문장들에서 어떤 의미를 갖는지 더 잘 파악할 수 있습니다.\n",
        "\n",
        "이 결과를 통해 어텐션 메커니즘이 입력된 정보들에서 중요한 부분을 더 강조하고, 전체적인 문맥을 구성해 나가는 방식을 이해할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "WbSvvBWqHoBS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ror60AFqI1PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAYgqH-R9Q19",
        "outputId": "b151512e-ec5f-44b4-ced7-d73081833f91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7e3981ec2770>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# 샘플 문장: \"나는 사과를 좋아해\", \"너는 바나나를 싫어해\", \"그는 포도를 먹었어\"\n",
        "sentences = [\n",
        "    [\"나는\", \"사과를\", \"좋아해\"],\n",
        "    [\"너는\", \"바나나를\", \"싫어해\"],\n",
        "    [\"그는\", \"포도를\", \"먹었어\"]\n",
        "]\n",
        "\n",
        "# Word2Vec 모델을 학습하여 각 단어의 임베딩 벡터 생성\n",
        "# vector_size=3: 각 단어를 3차원 벡터로 표현\n",
        "# min_count=1: 최소 단어 빈도가 1 이상인 단어만 포함\n",
        "# window=3: 주변 단어의 최대 거리\n",
        "# sg=0: CBOW(Continuous Bag of Words) 알고리즘 사용\n",
        "model = Word2Vec(sentences, vector_size=3, min_count=1, window=3, sg=0)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 각 토큰의 임베딩 벡터 추출\n",
        "# tokens 리스트에는 분석하고자 하는 단어들이 포함되어 있음\n",
        "tokens = [\"나는\", \"사과를\", \"좋아해\"]\n",
        "\n",
        "# Query 벡터 설정\n",
        "# \"나는\"에 해당하는 단어의 임베딩 벡터를 Query로 사용\n",
        "Q = model.wv[\"나는\"]\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1hI1hED9X2v",
        "outputId": "ade127d8-3239-4cb0-b4d3-441539693169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.21169634, -0.1135122 , -0.03154671], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLKN4NpW-rac",
        "outputId": "11dadd4b-8b4f-4da5-d06d-43abc6bfcf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Key 벡터 설정\n",
        "# 모든 토큰의 임베딩 벡터를 Key로 사용\n",
        "K = np.array([model.wv[token] for token in tokens])\n",
        "K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRDJF-ca9ebC",
        "outputId": "080ea43b-4bba-408d-faa5-ac266d5799e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.21169634, -0.1135122 , -0.03154671],\n",
              "       [ 0.16900873,  0.22525644,  0.02542885],\n",
              "       [-0.27617383, -0.3149606 ,  0.24372554]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Value 벡터 설정\n",
        "# 모든 토큰의 임베딩 벡터를 Value로 사용\n",
        "V = np.array([model.wv[token] for token in tokens])\n",
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk8j8uAU9qWR",
        "outputId": "957de0bc-f92d-4f29-af1a-17dd1242fadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.21169634, -0.1135122 , -0.03154671],\n",
              "       [ 0.16900873,  0.22525644,  0.02542885],\n",
              "       [-0.27617383, -0.3149606 ,  0.24372554]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 단계 1: Query와 Key 벡터의 내적을 통한 유사도 계산\n",
        "# 각 Key 벡터와 Query 벡터 간의 내적을 계산하여 유사도를 구함\n",
        "print(K.shape, Q.shape)\n",
        "dot_products = np.dot(K, Q)\n",
        "print(\"Dot Products (유사도 값):\", dot_products)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCG8fBcY9slw",
        "outputId": "f2537884-2ae5-43f6-95a9-1af7b686aeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3) (3,)\n",
            "Dot Products (유사도 값): [ 0.05869556  0.00940698 -0.03040186]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 단계 2: Softmax를 사용하여 가중치 계산\n",
        "# 유사도 값을 Softmax 함수에 통과시켜 각 단어의 가중치를 계산\n",
        "attention_weights = softmax(dot_products)\n",
        "print(\"Attention Weights (가중치):\", attention_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oPg1vbJ-Wjl",
        "outputId": "caa3d86f-a449-4324-ac9e-c5c1df8fe590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights (가중치): [0.34883764 0.3320608  0.3191015 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 단계 3: Value 벡터들의 가중합 계산\n",
        "# 각 Value 벡터에 가중치를 곱한 후 합산하여 최종 Attention 출력 계산\n",
        "attention_output = np.sum(attention_weights[:, np.newaxis] * V, axis=0)\n",
        "print(\"Attention Output (최종 출력):\", attention_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlJU-BzI-2QA",
        "outputId": "0cf082c4-d759-42b2-f6b8-7e90b2ed18ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Output (최종 출력): [ 0.04184134 -0.06530289  0.07521243]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 결과 해석하기\n",
        "# 각 토큰에 대해 가중치와 함께 출력하여 어떤 단어가 중요한지 확인\n",
        "for i, token in enumerate(tokens):\n",
        "    print(f\"Token: {token}, Weight: {attention_weights[i]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSnRyT0B-6Q-",
        "outputId": "6d1821ab-ca22-4565-d976-3ea2147ed1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 나는, Weight: 0.349\n",
            "Token: 사과를, Weight: 0.332\n",
            "Token: 좋아해, Weight: 0.319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 입력 시퀀스 (예: 3개의 토큰으로 구성된 시퀀스)\n",
        "# 각 행(row)은 하나의 토큰 시퀀스를 나타냅니다.\n",
        "input_sequence = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 1]], dtype=np.float32)\n",
        "\n",
        "# Query, Key, Value 행렬 정의\n",
        "# 여기서는 간단히 입력 시퀀스 자체를 Query, Key, Value로 사용합니다.\n",
        "# 일반적으로 Query, Key, Value는 서로 다를 수 있지만, 이 예제에서는 단순화를 위해 동일하게 설정합니다.\n",
        "query = input_sequence\n",
        "key = input_sequence\n",
        "value = input_sequence\n",
        "\n",
        "# 점수(스코어) 계산: query와 key의 전치 행렬을 곱합니다.\n",
        "# query와 key 사이의 유사도를 계산하는 것으로, 이를 통해 각 토큰 간의 연관성을 확인할 수 있습니다.\n",
        "# 점수 행렬의 각 요소는 해당 쿼리가 다른 토큰과 얼마나 관련 있는지를 나타냅니다.\n",
        "score = np.dot(query, key.T)\n",
        "\n",
        "# 소프트맥스 함수를 사용하여 어텐션 가중치를 계산합니다.\n",
        "# 소프트맥스를 통해 점수를 확률 분포로 변환하여 각 토큰이 얼마나 중요한지를 나타냅니다.\n",
        "attention_weights = tf.nn.softmax(score, axis=-1)\n",
        "\n",
        "# 어텐션 가중치와 value를 곱하여 최종 결과를 얻습니다.\n",
        "# 어텐션 가중치는 각 토큰의 중요도를 반영하여 value에 가중합을 적용합니다.\n",
        "output = np.dot(attention_weights, value)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Input Sequence:\")\n",
        "print(input_sequence)\n",
        "print(\"\\nAttention Weights:\")\n",
        "print(attention_weights.numpy())\n",
        "print(\"\\nOutput:\")\n",
        "print(output)\n",
        "\n",
        "\"\"\"\n",
        "결과:\n",
        "- Input Sequence는 입력된 토큰들로 구성된 행렬입니다.\n",
        "- Attention Weights는 입력 시퀀스 내에서 각 토큰이 다른 토큰과 얼마나 관련 있는지를 나타냅니다.\n",
        "- Output은 이러한 어텐션 가중치가 반영된 최종 표현입니다.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ZHadF9Bc9xps",
        "outputId": "429b1a02-d325-4ba9-d712-e38fb756f1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence:\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "\n",
            "Attention Weights:\n",
            "[[0.4683105  0.06337894 0.4683105 ]\n",
            " [0.15536241 0.42231882 0.42231882]\n",
            " [0.24472848 0.09003057 0.66524094]]\n",
            "\n",
            "Output:\n",
            "[[0.936621   0.53168947 0.936621  ]\n",
            " [0.57768124 0.84463763 0.57768124]\n",
            " [0.90996945 0.7552715  0.90996945]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n결과:\\n- Input Sequence는 입력된 토큰들로 구성된 행렬입니다.\\n- Attention Weights는 입력 시퀀스 내에서 각 토큰이 다른 토큰과 얼마나 관련 있는지를 나타냅니다.\\n- Output은 이러한 어텐션 가중치가 반영된 최종 표현입니다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 입력 시퀀스 (예: 3개의 토큰으로 구성된 시퀀스)\n",
        "# 각 행(row)은 하나의 토큰 시퀀스를 나타냅니다.\n",
        "input_sequence = np.array([[1, 0, 1, 0], [0, 1, 0, 1],\n",
        " [1, 1, 1, 1], [0, 0, 0, 1], [1,1,1,0]], dtype=np.float32)\n",
        "\n",
        "# Query, Key, Value 행렬 정의\n",
        "# 여기서는 간단히 입력 시퀀스 자체를 Query, Key, Value로 사용합니다.\n",
        "# 일반적으로 Query, Key, Value는 서로 다를 수 있지만, 이 예제에서는 단순화를 위해 동일하게 설정합니다.\n",
        "query = input_sequence\n",
        "key = input_sequence\n",
        "value = input_sequence\n",
        "\n",
        "# 점수(스코어) 계산: query와 key의 전치 행렬을 곱합니다.\n",
        "# query와 key 사이의 유사도를 계산하는 것으로, 이를 통해 각 토큰 간의 연관성을 확인할 수 있습니다.\n",
        "# 점수 행렬의 각 요소는 해당 쿼리가 다른 토큰과 얼마나 관련 있는지를 나타냅니다.\n",
        "score = np.dot(query, key.T)\n",
        "\n",
        "# 소프트맥스 함수를 사용하여 어텐션 가중치를 계산합니다.\n",
        "# 소프트맥스를 통해 점수를 확률 분포로 변환하여 각 토큰이 얼마나 중요한지를 나타냅니다.\n",
        "attention_weights = tf.nn.softmax(score, axis=-1)\n",
        "\n",
        "# 어텐션 가중치와 value를 곱하여 최종 결과를 얻습니다.\n",
        "# 어텐션 가중치는 각 토큰의 중요도를 반영하여 value에 가중합을 적용합니다.\n",
        "output = np.dot(attention_weights, value)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Input Sequence:\")\n",
        "print(input_sequence)\n",
        "print(\"\\nAttention Weights:\")\n",
        "print(attention_weights.numpy())\n",
        "print(\"\\nOutput:\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkrMB-A2_Wxh",
        "outputId": "8593ef1c-0f24-419c-bd6c-4ce889d29516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence:\n",
            "[[1. 0. 1. 0.]\n",
            " [0. 1. 0. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 1. 1. 0.]]\n",
            "\n",
            "Attention Weights:\n",
            "[[0.3057477  0.04137845 0.3057477  0.04137845 0.3057477 ]\n",
            " [0.04713718 0.34829926 0.34829926 0.12813213 0.12813213]\n",
            " [0.08015893 0.08015893 0.5922988  0.02948882 0.21789455]\n",
            " [0.09847517 0.26768324 0.26768324 0.26768324 0.09847517]\n",
            " [0.14409682 0.05301026 0.39169577 0.01950138 0.39169577]]\n",
            "\n",
            "Output:\n",
            "[[0.91724306 0.6528738  0.91724306 0.38850456]\n",
            " [0.5235686  0.82473063 0.5235686  0.82473063]\n",
            " [0.8903523  0.8903523  0.8903523  0.70194656]\n",
            " [0.46463355 0.63384163 0.46463355 0.8030497 ]\n",
            " [0.9274883  0.8364018  0.9274883  0.4642074 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Attention Weights: 첫 번째 행 [0.3057477, 0.04137845, 0.3057477, 0.04137845, 0.3057477]는 첫 번째 쿼리가 각 토큰에 대한 중요도를 나타냅니다\n",
        "\n",
        "---\n",
        "\n",
        "# 입력 시퀀스의 구조와 어텐션 메커니즘 설명\n",
        "\n",
        "## 1. 입력 시퀀스의 구조\n",
        "- 입력 시퀀스는 **5개의 토큰**으로 구성되어 있습니다.\n",
        "- 각 토큰은 **4개의 특성(feature)**을 가지고 있습니다.\n",
        "- 입력 시퀀스는 **5 x 4** 크기의 행렬로 나타납니다:\n",
        "  \n",
        "  ```\n",
        "  [[1, 0, 1, 0],   # 첫 번째 토큰\n",
        "   [0, 1, 0, 1],   # 두 번째 토큰\n",
        "   [1, 1, 1, 1],   # 세 번째 토큰\n",
        "   [0, 0, 0, 1],   # 네 번째 토큰\n",
        "   [1, 1, 1, 0]]   # 다섯 번째 토큰\n",
        "  ```\n",
        "  \n",
        "  - **5 (행)**: 입력 토큰의 개수\n",
        "  - **4 (열)**: 각 토큰의 특성(feature) 개수\n",
        "\n",
        "## 2. Query, Key, Value 정의\n",
        "- 이 예제에서는 입력 시퀀스를 **Query**, **Key**, **Value**로 동일하게 사용합니다.\n",
        "- 따라서 Query, Key, Value 모두 **5 x 4** 크기의 행렬입니다.\n",
        "\n",
        "## 3. 점수(Score) 계산\n",
        "- 어텐션 메커니즘에서 **점수(score)**를 계산할 때는 Query와 Key의 전치 행렬을 곱합니다.\n",
        "  - Query의 크기: **(5, 4)**\n",
        "  - Key의 전치 행렬의 크기: **(4, 5)**\n",
        "  - 점수 행렬의 결과 크기: **(5, 5)**\n",
        "- 이 점수 행렬의 각 원소는 **각 Query 토큰과 모든 Key 토큰 사이의 유사도**를 나타냅니다.\n",
        "\n",
        "## 4. Attention Weights 계산\n",
        "- 점수 행렬에 Softmax를 적용하여 **Attention Weights**를 구합니다.\n",
        "- 이 Attention Weights 행렬의 크기도 **(5, 5)**가 되며, 각 행은 특정 Query 토큰이 모든 Key 토큰과의 관계를 나타냅니다.\n",
        "\n",
        "## 5. 첫 번째 행의 해석\n",
        "- 예를 들어, 아래와 같은 Attention Weights가 있다고 가정해봅시다:\n",
        "  \n",
        "  ```\n",
        "  Attention Weights:\n",
        "  [[0.3057477, 0.04137845, 0.3057477, 0.04137845, 0.3057477],\n",
        "   [0.04713718, 0.34829926, 0.34829926, 0.12813213, 0.12813213],\n",
        "   ...]\n",
        "  ```\n",
        "  \n",
        "- 첫 번째 행 **[0.3057477, 0.04137845, 0.3057477, 0.04137845, 0.3057477]**는 **첫 번째 Query 토큰이 모든 Key 토큰에 대해 얼마나 관련이 있는지**를 나타냅니다.\n",
        "  - 첫 번째 Query 토큰이 **첫 번째, 세 번째, 다섯 번째 Key 토큰**과의 유사도가 높고 (값이 **0.3057477**), **두 번째와 네 번째 Key 토큰**과의 유사도가 낮음을 (값이 **0.04137845**) 알 수 있습니다.\n",
        "- 여기서 주의해야 할 점은 **이 행의 원소가 5개인 이유**는 입력에 **5개의 토큰**이 있기 때문입니다. 따라서, 어텐션 가중치 행렬은 각 Query 토큰이 **전체 입력(5개의 Key 토큰)**과의 관계를 나타내기 위해 **5 x 5**의 크기를 갖습니다.\n",
        "\n",
        "## 결론\n",
        "- 입력 시퀀스의 크기는 **(5, 4)**입니다. 여기서 **5**는 토큰의 개수이고, **4**는 각 토큰의 특성(feature)의 개수입니다.\n",
        "- **Attention Weights**의 크기가 **5 x 5**인 이유는, 각 Query 토큰이 모든 Key 토큰과의 관련성을 계산하기 때문입니다.\n",
        "- 첫 번째 행 **[0.3057477, 0.04137845, 0.3057477, 0.04137845, 0.3057477]**는 첫 번째 Query 토큰이 전체 **5개의 Key 토큰**과 얼마나 연관이 있는지에 대한 정보입니다.\n",
        "- 어텐션 메커니즘은 각 토큰 간의 관계를 전체적으로 고려하기 때문에 어텐션 가중치 행렬의 각 행에는 **전체 입력 토큰 개수만큼의 원소**가 포함됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "이제 마크다운 형식으로 설명이 더 명확해졌기를 바랍니다. 필요한 다른 부분이나 추가적인 질문이 있으면 언제든지 알려주세요!"
      ],
      "metadata": {
        "id": "ug-Gx5f2BHPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 간단한 입력 시퀀스\n",
        "inputs = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]], dtype=np.float32)  # 3개의 입력 시퀀스, 길이는 3\n",
        "\n",
        "# 가중치를 랜덤하게 초기화 (실제 어텐션에서는 학습됨)\n",
        "weights = tf.Variable(tf.random.normal([inputs.shape[-1]]))\n",
        "print(weights)\n",
        "# 어텐션 점수 계산 (입력과 가중치의 내적)\n",
        "attention_scores = tf.nn.softmax(tf.reduce_sum(inputs * weights, axis=1))\n",
        "print(attention_scores)\n",
        "# 어텐션 스코어를 이용한 출력 계산\n",
        "context_vector = tf.reduce_sum(tf.expand_dims(attention_scores, -1) * inputs, axis=0)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"입력 시퀀스:\")\n",
        "print(inputs)\n",
        "print(\"어텐션 스코어:\")\n",
        "print(attention_scores.numpy())\n",
        "print(\"컨텍스트 벡터:\")\n",
        "print(context_vector.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0RpsatiFMsB",
        "outputId": "3538951b-4fdf-4912-f00c-5fa0a3481678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([-1.2322834 , -0.68503356, -1.9497645 ], dtype=float32)>\n",
            "tf.Tensor([0.15947355 0.27564886 0.56487757], shape=(3,), dtype=float32)\n",
            "입력 시퀀스:\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]]\n",
            "어텐션 스코어:\n",
            "[0.15947355 0.27564886 0.56487757]\n",
            "컨텍스트 벡터:\n",
            "[0.7243511  0.84052646 0.43512243]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPzX-Q5-O5Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rlu5SxN5Hh-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqPVbYjHHiAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMsbUJUyHiCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def attention(query, key, value):\n",
        "    # Step 1: Calculate Scores (Scaled Dot-Product)\n",
        "    d_k = key.shape[-1]  # dimension of key\n",
        "    scores = np.dot(query, key.T) / np.sqrt(d_k)\n",
        "\n",
        "    # Step 2: Apply Softmax to get Attention Distribution\n",
        "    attention_weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n",
        "\n",
        "    # Step 3: Calculate Attention Value by weighted sum of Value vectors\n",
        "    attention_value = np.dot(attention_weights, value)\n",
        "\n",
        "    return attention_value, attention_weights\n",
        "\n",
        "# Example inputs\n",
        "query = np.array([[1, 0, 1]])\n",
        "key = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n",
        "value = np.array([[10, 0], [0, 10], [10, 10]])\n",
        "\n",
        "# Run attention\n",
        "attention_value, attention_weights = attention(query, key, value)\n",
        "\n",
        "# Display results\n",
        "print(\"Attention Weights:\\n\", attention_weights)\n",
        "print(\"Attention Value:\\n\", attention_value)"
      ],
      "metadata": {
        "id": "Qh5C1mY2HiF3",
        "outputId": "a5e4e6d3-bbfb-4ece-f771-ab95feb9a46b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights:\n",
            " [[0.53289684 0.16794345 0.29915971]]\n",
            "Attention Value:\n",
            " [[8.3205655  4.67103162]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=6s69XY025MU&t=605s"
      ],
      "metadata": {
        "id": "t3cdf3QJHjBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>**각 픽셀이 단어라고 가정하고 7이라는 글자(문장)는 각 픽셀(단어)의 중요도(밝은색)를 다르게 Attension)**\n",
        "<img src='https://user-images.githubusercontent.com/68524289/117996078-cf4a4600-b37c-11eb-9d6d-c1e872ce0bd9.png'>\n",
        "\n",
        "<img src ='https://user-images.githubusercontent.com/68524289/117996596-3e279f00-b37d-11eb-8139-ba09f78a504b.png'>\n",
        "\n",
        "<img src='https://user-images.githubusercontent.com/68524289/117996613-41228f80-b37d-11eb-9391-12ee37263343.png'>\n",
        "\n",
        "- **Attention Mask: 입력 이미지에서 특정 영역의 중요도를 표현한 \"활성화 맵\"으로 중요한 영역을 강조하여 모델의 학습 방향을 해석**\n",
        "\n",
        "- **Attention Map: Attention Mask를 원본 이미지와 결합한 형태로, 모델이 실제로 어디에 주목하고 있는지를 시각적으로 명확히 보여주며 이 맵은 원본 이미지 위에 주목을 표현하기 때문에 해석이 좀 더 직관적**"
      ],
      "metadata": {
        "id": "f3J3ceHjR6CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        self.feature_map = x  # Store feature map for attention visualization\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=True)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "model.eval()\n",
        "\n",
        "# Function to visualize attention map\n",
        "def visualize_attention(image, attention_map, title):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
        "    axs[0].imshow(image.squeeze(), cmap='gray')\n",
        "    axs[0].set_title('Original')\n",
        "    axs[1].imshow(attention_map, cmap='viridis')\n",
        "    axs[1].set_title('Attention Mask')\n",
        "    axs[2].imshow(image.squeeze(), cmap='gray')\n",
        "    axs[2].imshow(attention_map, cmap='viridis', alpha=0.6)\n",
        "    axs[2].set_title('Attention Map')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of test data\n",
        "examples = iter(test_loader)\n",
        "images, labels = next(examples) # Use next(examples) instead of examples.next()\n",
        "\n",
        "# Forward pass through the model\n",
        "images = images.to(device)\n",
        "output = model(images)\n",
        "\n",
        "# Get the feature map from the model\n",
        "feature_map = model.feature_map.detach().cpu().numpy()[0]\n",
        "attention_map = np.mean(feature_map, axis=0)  # Average across channels to get attention\n",
        "\n",
        "# Visualize the attention map\n",
        "visualize_attention(images.cpu(), attention_map, title=f'MNIST Attention Map - Label: {labels.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oAE8a0nQR6aV",
        "outputId": "38c2a62f-45ae-4187-d27f-f8becd6cbf2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 4.97MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 159kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.18MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWpylCgWR7IW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}