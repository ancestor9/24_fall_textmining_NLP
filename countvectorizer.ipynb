{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBnBfF5g5GXBYw9qxc8R+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/24_fall_textmining_NLP/blob/main/countvectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()\n",
        "print(X.toarray())\n",
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "vectorizer2.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9VcnlTnH-CG",
        "outputId": "5f4b9683-11b1-4192-f008-31cfb888c2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
              "       'second document', 'the first', 'the second', 'the third',\n",
              "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR0EXJLRHqww",
        "outputId": "66b96e7a-656d-4eb8-8417-d0167bddf937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "긍정적 리뷰에서 자주 등장하는 바이그램\n",
            "['00 for' '000 000' '000 and' ... 'zwigoff brilliant' 'zycie masterfully'\n",
            " 'zycie za']\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "부정적 리뷰에서 자주 등장하는 바이그램\n",
            "['00 am' '00 feet' '00 for' ... 'zwick thinks' 'zwigoff superb'\n",
            " 'zzzzzzz critique']\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# NLTK 데이터 다운로드 (처음 실행 시)\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "# 긍정적 리뷰와 부정적 리뷰의 파일 ID를 분리\n",
        "positive_ids = movie_reviews.fileids('pos')\n",
        "negative_ids = movie_reviews.fileids('neg')\n",
        "\n",
        "def get_text_from_ids(ids):\n",
        "    return [' '.join(movie_reviews.words(file_id)) for file_id in ids]\n",
        "\n",
        "# 긍정적 리뷰와 부정적 리뷰의 텍스트 데이터 준비\n",
        "positive_texts = get_text_from_ids(positive_ids)\n",
        "negative_texts = get_text_from_ids(negative_ids)\n",
        "\n",
        "# CountVectorizer 설정: 바이그램(2-그램) 추출\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "\n",
        "# 긍정적 리뷰 바이그램 분석\n",
        "X_pos = vectorizer.fit_transform(positive_texts)\n",
        "print(\"긍정적 리뷰에서 자주 등장하는 바이그램\")\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X_pos.toarray())\n",
        "\n",
        "# 부정적 리뷰 바이그램 분석\n",
        "X_neg = vectorizer.fit_transform(negative_texts)\n",
        "print(\"\\n부정적 리뷰에서 자주 등장하는 바이그램\")\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X_neg.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVlaA6olHszT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}